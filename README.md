# Ensemble Learning

This repository stores the [Jupyter notebook][ipynb] for an In-Class Exercise (ICE) I wrote for the weekly sharing/peer-coaching/co-learning lessons on Machine Learning (ML) topics for SMU BIA's DAP. Ensemble Learning was covered that particular week. 

For this ICE, we explored a [dataset][cars] on cars found on [Kaggle][kaggle]. Our main task was predicting (classification) of which country a car is produced in based on sttributes such as miles per gallon, cylinders, horsepower etc.

*The [dataset's page][kaggle] on Kaggle gives more information on the attributes used.* 

___

## Contents

### Recap on Decision Trees

We had a brief recap on Decision Trees covered in a lesson prior, including how to implement it, visualize it and its decision boundaries, and display the order of feature importance it has learnt. 

### EDA

We first did some Exploratory Data Analysis (EDA) where we looked at the correlation of features, distribution of each feature, class representation etc. 

### Implementation of Ensemble Methods

We then moved on to implementing different ensemble learning methods, such as random forests, adaboost etc. 

### Hyperparameter tweaking

We also observed how to tweak hyperparameters and plot out performance metrics comparing different models. 

___

[ipynb]: ./ensemble-learning-cars-master.ipynb
[cars]: ./cars.csv
[kaggle]: https://www.kaggle.com/abineshkumark/carsdata